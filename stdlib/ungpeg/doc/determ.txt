--------------------------------------------

S <- (' '/'\t'/'\n'/'\r')*
S <-- star1
star1 <-- ([ ]/[\t]/[\n]/[\r]) star1 / succ
# TODO: Need a rule/transform to make sure star1 swaps into place of S
#  done: see NOTE ON STAR REDUCTION IN PLACE below

S | [ ]  |-> S
  | [\t] |-> S
  | [\n] |-> S
  | [\r] |-> S
  | _    |-> succ


--------------------------------------------

number    <- int frac? exp?                                ->      (num $1 $2)
int       <- d:'-'? (d:nz_digit d:digit+) / d:digit        ->               $d
frac      <- '.' digit+                                    ->        (frac $2)
exp       <- e digit+                                      ->        (e $e $2)
e         <- [eE] ('+' / '-')?                             ->               $2
nz_digit  <- [1-9]
digit     <- [0-9]

number <- 1-number:(d-int:[-]? (d-int:[1-9] d-int:([0-9] [0-9]*)) / d-int:[0-9])
          2-number:([.] 2-frac:([0-9] [0-9]*))?
	  (e-exp:(([e]/[E]) 2-e:([+]/[-])?) 2-exp:([0-9] [0-9]*))?

number <- ([-]? [1-9] [0-9] [0-9]* / [0-9])
          ([.] [0-9] [0-9]*)?
	  (([e]/[E]) ([+]/[-])? [0-9] [0-9]*)?

number <- ( ([-] [1-9] [0-9] [0-9]*) /
            ([1-9] [0-9] [0-9]*) /
	    [0-9]
	  )
	  ([.] ...)
	  ([e] ...)
	  ([E] ...)
	  (_ -> succ)


== non-labeled & no transforms/collapse ==

number  | [-]         |-> [1-9] [0-9] star1 number2
        | [1-9] [0-9] |-> star1 number2             # Overlap so second one necessary
        | [0-9]       |-> number2                   # Overlap with previous
	| _           |-> fail

number2 | [.]         |-> [0-9] star1 number3
        | _           |-> number3

number3 | [eE] [+]    |-> [0-9] star1 succ
        | [eE] [-]    |-> [0-9] star1 succ
        | [eE] [0-9]  |-> star1 succ
        | _           |-> succ

star1   | [0-9]       |-> star1
([0-9]*)| _           |-> succ

# TODO: possibly automatically abstract out common runs if there are enough of
# them / they are big enough to warrant it. (e.g., 'star1 succ')

# TODO: actually, star1 is guaranteed to succeed, so star1 succ is redundant-
# except collapse and transformations may affect it.

# Technically you can pull 4 bytes out at once and jump that far into the
# stream, but in reality there are so many choices by then that the decision
# logic and program size would undo any benefits...
[-]   [1-9] [0-9] [0-9] -> [0-9]*
[-]   [1-9] [0-9] [.]   -> ...
[-]   [1-9] [0-9] [eE]  -> ...
[-]   [1-9] [0-9] _     -> succ
[1-9] [0-9] [0-9] [0-9] -> [0-9]*
[1-9] [0-9] [0-9] _     -> succ
[1-9] [0-9] _     _     -> succ
...
# So the rule is: Pull the least amount possible that allows you to branch.(?)

--------------------------------------------

comment_lang  <- S* 'hi!' S*
S             <- (SPACE / NL)+
NL            <- COMMENT? NEWLINE
NEWLINE       <- "\n" / "\r\n" / "\r"
SPACE         <- [ \t] / ML_COMMENT
COMMENT       <- "#" (!NEWLINE .)* &NEWLINE
ML_INNER      <- ML_COMMENT / (!"#|" !"|#" .)+
ML_COMMENT    <- "#|" ML_INNER* "|#"

comment_lang <-- star1 'hi!' star1
ML_COMMENT   <-- '#|' (ML_COMMENT / (!('#|'/'|#') any) (!('#|'/'|#') any)*)* '|#'
star1        <-- (   [ ]
                   / [\t]
		   / ML_COMMENT
                   / ([#] (!([\n]/'\r\n'/[\r]) any)* &([\n]/'\r\n'/[\r]))? ([\n]/'\r\n'/[\r])
		 ) star1 / succ

!([\n]/'\r\n'/[\r]) ---- '\r\n' is redundant- but how? (see answers below)
!([\n\r])

comment_lang <-- star1 'hi!' star1
ML_COMMENT   <-- '#|' (ML_COMMENT / (!('#|'/'|#') any) (!('#|'/'|#') any)*)* '|#'
star1        <-- ( [ \t]
		   / ML_COMMENT
                   / ([#] (![\n\r] any)* &([\n\r]))? ([\n]/'\r\n'/[\r])
		 ) star1 / succ

comment_lang <-- star1 'hi!' star1
ML_COMMENT   <-- '#|' (ML_COMMENT / (!('#|'/'|#') any) (!('#|'/'|#') any)*)* '|#'
star1        <-- ( [ \t]
		   / ML_COMMENT
                   / ([#] [^\n\r]* &([\n\r]))? ([\n]/'\r\n'/[\r])
		 ) star1 / succ

!('#|'/'|#') any
# weak backtracking - two bytes compared before only one consumed - can't think
# of any other way to do it though at the moment...


----------------------------------- Removing redundant predicate terms
z <- !( abc / ab / a )
z <-- !( a (bc / b / succ))
z <-- !( a (b (c / succ) / succ))
z <-- !( a (b c?)?)
z <-- !a (see two proofs below)

proof 1
********!!!!!  Predicate normalization: all trailing 's' ('1' or '0')
expressions treated as if they were 'succ' ('0') - which means they can be
removed completely (since succ at end of seq is implied)

!(a b?) == !a (because b? always succeeds)
!(a b*) == !a
!(a b? c) == !(a b? c) (because second term isn't trailing)

proof 2
*********!!!! A predicated ord is commutative
z <- !(a/b/c)
z <- !a !b !c
all three predicates get applied from the same position - regardless of order
in original ord.
therefore:
!(a/b/c) == !(b/c/a) == ...


(Asside)
(the following doesn't reduce further, that I can tell)
!(a / b c? d)
!(a / b c d / b d)

************ Therefore, in a trailing ord in a predicate, any expression that
is has any other expression as a prefix (or equal) can/should be removed.
proof:
They are commutative so you can always commute the smaller expression to the
left of the larger one, in which case the larger one is never reachable.


--------------------------------------------

e <- f1 f2 f3

f1 <- e1 / e2 / e3
f2 <- e1 e2 e3
f3 <- e1? e2 e3 #== e1 e2 e3 / e2 e3

e1 <- t1 t2 t3
e2 <- t1 / t2 / t3
e3 <- t1? t2 / t3 #== t1 t2 / t2 / t3

t1 <- [a]
t2 <- 'bcd'
t3 <- [e]

e <- ( [a] 'bcd' [e] / [a] / 'bcd' / [e] / [a]? 'bcd' / [e] )
     ( ([a] 'bcd' [e]) ([a] / 'bcd' / [e]) ([a]? 'bcd' / [e])   )
     ( ([a] 'bcd' [e])? ([a] / 'bcd' / [e]) ([a]? 'bcd' / [e])  )


e <-- ( [a] 'bcd' [e] / [a] / 'bcd' / [e] / [a] 'bcd' / 'bcd' / [e] )
e <-- ( [a] 'bcd' [e] / [a] / 'bcd' / [e] )
e <-- ( [a] ('bcd' [e] / succ) / 'bcd' / [e] )

d(t1) = [a]
d(t2) = 'bcd'
d(t3) = [e]

d(e1) = d(t1) = [a]
d(e2) = d(t1)/d(t2)/d(t3) = [a]/'bcd'/[e]
d(e3) = d(t1)/d(t2)/d(t3) = [a]/'bcd'/[e]

d(f1) = d(e1)/


!!!***********     e1? rest == e1 rest / rest   !!  Much better than (e1 / succ) rest
              (it seems) because it gives us a static determinant

e1 e2 e3? e4 e5 == e1 e2 (e3 e4 e5 / e4 e5)

e1 e2 expr? expr e4 == e1 e2 (expr expr e4 / expr e4) == e1 e2 expr (expr e4 / e4)
(also == )  e1 e2 expr expr? e4


expr?      ---> expr / succ      <--- only if it's the last term in an ord
expr? rest ---> expr rest / rest <--- anywhere else


e1/e2?/e3  --> already not allowed-  e3 never succeeds


*******  Worth it to do the same with star expressions?

e1 e2* e3 == e1 (e2 e2* e3 / e3)
e1 e2* e3 == e1 (&e2a e2* e3 / e3)


******
Predicates - can reduce to 'QUALIFIER' as long as every possibility is a static
terminal or has variable length less than 5 bytes...

!([a]/[b]/[c])         == Q([^abc])
!([a] [b] [c] [d] [e]) == Q(^'abcde')
!([a] [b]? [c] [d])    == Q(^


e <- !'abcde' 'abcd'

e <-- 'abcd' ![e]

case ... of
  <<_:Idx/bytes, 97,98,99,100,C, _/bytes>> when C =/= 101 -> ...
  ...
end
# very weak form of backtracking if it fails (will look up those bytes again).
# Possibly acceptable.

BUT

e <- !'abcde' 'abcd' / 'abcdefg'

REORDERER

e <-- 'abcdefg' / 'abcd'
e <=- 'abcd' ('efg' / succ)

grammar    <- rule* eof
rule       <- symbol LEFTARROW expression
expression <- (symbol !LEFTARROW)*
symbol     <- [a-z]
LEFTARROW  <- '<-'
---
grammar <- ([a-z]'<-' ([a-z]!'<-')*)*  eof

e <- (a b (a !b)*)*
(OR) e <-  stuff:(start:ab body:(a!b)*)*

e <-- ab e2 e / succ
e2<-- a!b e2 / succ

e <-- ab e2 e / succ
e2<-- a!b e2 / e     # Pull in tail from context
                     # don't need / succ because e always succeeds
e <-- ab e2 e / succ
e2<-- a!b e2 / (ab e2 e / succ)

# e2 now has full e, so e2 e is now redundant
e <-- ab e2 / succ
e2<-- a!b e2 / (ab e2 / succ)

e <-- ab e2 / succ
e2<-- a!b e2 / ab e2 / succ  # next is reorder first to terms

e <-- ab e2 / succ
e2<-- ab e2 / a e2 / succ
(OR) e2 <-- start:ab e2 / body:a e2 / succ

e <-- ab e2 / succ
e2<-- a (b e2 / e2) / succ
(OR) e2 <-- start:body:a (b {start} e2 / {body} e2) / succ

abaaaabaaabab
^    ^   ^ ^
'ab' : e[1,1] match, call e2 (collapse as start)
'a'  : e2[1,1] match, call e2[1,2]  (collapse as body)
'a'  : e2[1,2] -> e2[1,1], match, call e2[1,2]  (collapse former as body)
'a'  : e2[1,2] -> e2[1,1], match, call e2[1,2]  (collapse former as body)
'a'  : e2[1,2] -> e2[1,1], match, call e2[1,2]  (collapse former as body)
'b'  : e2[1,2,1] match, (collapse as start), call e2
...

******
SO:
e <- (a b (a !b)*)*

e <=- a b f / succ
f <=- a (b f / f) / succ


grammar    <- rule* eof
rule       <- symbol LEFTARROW expression
expression <- (symbol !LEFTARROW)*
symbol     <- [a-z]
LEFTARROW  <- '<-'

grammar <-- ([a-z]'<-' ([a-z] !'<-')*)*  eof

grammar <=- [a-z] '<-' g2 / eof
g2      <=- [a-z] ('<-' g2 // g2) / succ



******
Hypothesis: predicates --> atomic qualifier, reorder, or dead-code simplification (only)

---
Tricky:
# Tricky because the predicate phrase doesn't seem to match up exactly with the
# next term.

e <-  &([a] b) [a] c
b <-  [1] / [2] / [3]
c <-  [0-9]

qualifier

e <- [a] &([1-3]) [0-9]

e <- [a] [1-3]

(obviously a useless expression _unless_: )
e <-  &([a] b) [a] c  -> $c
b <-  special:([1] / [2] / [3])
c <-  [0-9]


---
Trickier:
# Much tricker- requires new form because of the non-tail-recursive
# accumulation phase in 'y' and 'z' ('y' in particular).
# (BTW, this matches  a^n b^n c^n )
# Hopefully it ends up being a qualifier- but in this case it's qualifying on a
# meta-level- the quantity.

x <-  &y [a]* z
y <-  [a] y [b] / succ
z <-  [b] z [c] / succ

x <-- &y w z
y <-- [a] y [b] / succ
z <-- [b] z [c] / succ
w <-- [a] w / succ

x <-- &y w z
y <-- [a] self [b] / succ
z <-- [b] self [c] / succ
w <-- [a] self / succ

x <-- &y w
y <-- [a] self [b] / succ
w <-- [a] self / z
z <-- [b] self [c] / succ

---
Trickier Yet:
# (Like above but has the extra qualifier to make sure 'b' doesn't overflow its
# bounds [strictly not necessary?] - anyway, it's the non cfg example from the
# original peg paper)

x <-  &(y ![b]) [a]* z eof
y <-  [a] y [b] / succ
z <-  [b] z [c] / succ

x <-- &(y ![b]) w z eof
y <-- [a] y [b] / succ
z <-- [b] z [c] / succ
w <-- [a] w / succ

---------
Also tricky:

z <- !'ababababa1' !'ababababa2' 'ababababa'
or even
z <- !'ababababa1' !'ababababa2' any

always seems to require weak backtracking

BUT - these are only valid if they can be boiled down to reordering actions
(i.e.- that's the only real use anyone would have for them).


******
New form: {tag}           = [internal] Collapse accumulator into specified tag
	  {tag*}          = ? [internal] Collapse accumulator and add to tag's
	                    accumulator
	  {|transformer|} = [internal] execute transformation (but only if it
			    is used later on in another one) (either the
			    expression or rule name inside)
	  ~ prefix        = [internal] do not aggregate
	  //              = [internal] xord separator
	  `external`      = replaced at runtime with return value of general
	                    expression inside - which is given the state object
			    and the current accumulator (or acc stack- whatever
			    it turns out to be)...
          {<<}            = [internal] left-recursion check mechanism

(internal form, that is- not for use in the wild)
tag* -> for star and plus expressions or when multiple things tagged manually (?)

Or maybe:
 on collapse:  already one in there?  add another- now it's a list (or maybe
               always treat it as a list but then singularize it @ transform time)
 on transform: clear out all data that's used in the transform
               (unless it's referenced higher up?)

e <- tag1:e2 -> trsf1
e <-- tag1:e2 {tag1} {/trsf1/}

-----
tags for: position, labels, rules



******
I'm thinking that auto-transforms for building an AST might be feasable after
all- especially if the children ones aren't executed unless they're used...

e <- a b         #(implied) -> {e,Pos,$_}
a <- 'abc'       #(implied) -> {a,Pos,$_}
b <- 'bcd'       #(implied) -> {b,Pos,$_}
input: 'abcbcd'
{e, {1,1}, {{a, {1,1}, 'abc'}, {b, {1,1}, 'bcd'}}}

BUT -
e <- a b -> {here_you_go, $1}
a <- 'abc'       #(implied) -> {a,Pos,$_}
b <- 'bcd'       #(implied) drop
input: 'abcbcd'
{here_you_go, {a, {1,1}, 'abc'}}

e <- A b         #(implied) -> {e,Pos,$_}
A <- 'abc'       #(implied) drop because it's a token
b <- 'bcd'       #(implied) -> {b,Pos,$_}
input: 'abcbcd'
{e, {1,1}, {b,{1,4},'bcd'}}

Except, maybe simple literals shouldn't be ast-wrapped like that...

******
Thought: $_ as tuple but %_ as list? (or something)

****** NOTE ON STAR REDUCTION IN PLACE
e <-  something* rest
e <-- something e / rest
(including the case when "rest" is 'succ')

******
to prove: lookahead on terminal does not affect constant space / linear time complexity

******
NOTE: Possibly simplifies things (for users' understanding) if predicates are
completely invisible to transformation expressions. (problem might be when
they're counting the terms...)


-----------------------------------------------------

number    <- int frac? exp?                                ->   (num $1 $2 $3)
int       <- d:'-'? (d:nz_digit d:digit+) / d:digit        ->               $d
frac      <- '.' digit+                                    ->        (frac $2)
exp       <- e digit+                                      ->        (e $e $2)
e         <- [eE] ('+' / '-')?                             ->               $2
nz_digit  <- [1-9]
digit     <- [0-9]


number    <- 1_number:int {1_number} 2_number:frac? {2_number}
             3_number:exp? {3_number} {>(num $1_number $2_number $3_number)<}
int       <- (d_int:'-'? (d_int:nz_digit d_int:digit+) / d_int:digit)
             {d_int} {>$d_int<}
frac      <- '.' 2_frac:digit+ {2_frac} {>(frac $2_frac)<}
exp       <- e_exp:e {e_exp} 2_exp:digit+ {2_exp} {>(e $e_exp $2_exp)<}
e         <- [eE] 2_e:('+'/'-')? {2_e} {>$2_e<}
nz_digit  <- __nz_digit:[1-9] {__nz_digit} {>$__nz_digit<}
digit     <- __digit:[0-9] {__nz_digit} {>$__digit<}




z <-  a:(c d e) / b:(c d) / c:c -> ($a $b $c)
z <-- (c d e {z_a} / c d {z_b} / c {z_c}) {>($z_a $z_b $z_c)<}
z <-- (c (d e {z_a} / d {z_b} / {z_c})) {>($z_a $z_b $z_c)<}
z <-- (c (d (e {z_a} / {z_b}) / {z_c})) {>($z_a $z_b $z_c)<}

z <-  t:a+ b u:a* -> ($t $u)
z <-- a+ {z_t} ~b {>$z_t<}
z <-- a a* {z_t} {>$z_t<}
z <--

z <-  t:'ones' / u:'one' / v:'only' / w:any+ -> ($t $u $v $w)
z <-- ('ones' {z_t} / 'one' {z_u} / 'only' {z_v} / any any* {z_w}) {|($t $u $v $w)|}
z <-- ('on' ('es' {z_t} / 'e' {z_u} / 'ly' {z_v} / any* {z_w}) / any any* {z_w}) {|z|}
[z <- 'on' ('es' / 'e' / 'ly' / any*) / any+ ]
[z <- 'on' ('e' ('s' // succ) // 'ly' // any*) // any+ ]
z <-- ('on' ('e' ('s' {z_t} // {z_u}) // 'ly' {z_v} // any* {z_w}) // any any* {z_w}) {|z|}

z <=- ('on' ('e' ('s' {z_t} // {z_u}) // 'ly' {z_v} // y {z_w}) // any y {z_w}) {|z|}
y <=- any y / succ


z <- (a:[y]/b:[x]/c:[w])+ -> ($a $b $c)
input: yxwwwwyxxyxywwyxyx
output: {[yyyyyy], [xxxxxx], [wwwwww]}



w <- dig x     -> $dig
x <- '-' dig*  -> $dig
dig <- [0-9]

w <-- dig-w:[0-9] ([-] dig-x:[0-9]*)
w <=- [0-9] {dig-w} ~[-] [0-9]* {dig-x} {|x|} {|w|}


* When inlining- inlined body always comes _before_ the current transform

* Warning if tags aren't used
* Labels used "upstream"?

* Transform function also cleans out anything remaining in accumulator (?)

e <- a -> T
e <- a|T

e <- a b c -> T
e <-- a b c|T



e <- a b / c b -> $2 (illegal)

e <- a T:b / V:c b -> $T
e <-- ~a T:b / V:c ~b -> $T
BUT
e <- a T:b / V:c b -> $_
e <-- a b / c b -> $_

----
OVERLAPPING REFERENCES WHEN FACTORING TO XORDS

e <-  T:(ab) U:(cd) V:(ef) g / abc T:(def) -> $T $U $V
e <-- ab-{T} cd-{U} ef-{V} g-{~} {|e|}
    / abc-{~} def-{T} {|e|}
e <-- ab-{?T1} c-{?~1} d-{?U1} ef-{?V1}-{?T2} 
       (g-{T1}-{U1}-{V1}-{~} succ-{|e|} / succ-{~1}-{T2}-{|e|})

* When a function can only be commuted from one side, make a new 'tentative'
  marker, which, at runtime, will mark the size of the accumulator at that
  moment. At the same time, an 'execute' marker is added to the tail of
  functions on the head of the clause the expression was commuted from (but
  before the transformation function if it's there). If it ever hits an
  'execute' marker it will pull that much off the front of the accumulator,
  assign it, remove the tentative variable, and decrement that amount from any
  remaining tentatives.
  EDIT: Attach 'execute' marker to an 'nop' (succ for seq's) that's at the head
  of the term where the tentative's term was extracted, and skip those nops
  when looking at subsequent terms to factor out. (see example below)

* It seems helpful currently to attach the final transformation function to
  dangling succ clauses. (or maybe nop at the head can take over...)

* When checking for duplicate terms in an ord (and, probably, most
  normalization rules), ignore functions

AFTER XORD TRANSFORMATIONS (?):
* {~} gets attached to _all_ terms where appropriate. (so, for example, above's
  `abc-{~}` should actually be `a-{~} b-{~} c-{~}`)
* A {~} on an expression propagates to all its children (creating a call to a
  new non-accumulate versions of rules if necessary). Probably a very similar
  algorithm to predicate propagation.
* Now the final parser can avoid making unnecessary accumulations in the first
  place- so the {~} becomes more of a "don't accumulate on this term" prefix
  instead of a "throw-away" suffix except when it has turned into a
  "tentative"/"execute" pair.


BEST EXAMPLE
- Shows overlapping
- Shows non-accumulation
- Keeps non-accumulation in such a way that afterward they can be optimized
  just like predicate terms.

e <-  T:(ab) U:(cd) V:(ef) g / abc T:(def) -> $T $U $V

e <--  ab-{T} cd-{U} ef-{V} g-{~} succ-{|e|}
    / a-{~} b-{~} c-{~} def-{T} succ-{|e|}

e <-- a-{?~1} (b-{T} cd-{U} ef-{V} g-{~} succ-{|e|}
              / nop-{~1} b-{~} c-{~} def-{T} succ-{|e|})

e <-- a-{?~1} b-{?T1|?~2} (nop-{T1} cd-{U} ef-{V} g-{~} succ-{|e|}
                          / nop-{~1} nop-{~2} c-{~} def-{T} succ-{|e|})

# But now {~2} subsumes {~1} because they're next to each other (on the right),
# so ~1 (both the tentative and the execute) can be removed.

e <-- a b-{?T1|?~2} (nop-{T1} cd-{U} ef-{V} g-{~} succ-{|e|}
                    / nop-{~2} c-{~} def-{T} succ-{|e|})

e <-- a b-{?T1} c-{?~3} (nop-{T1} d-{U} ef-{V} g-{~} succ-{|e|}
                        / nop-{~3} d e f-{T} succ-{|e|})

e <-- a b-{?T1} c-{?~3} d-{?U1} (nop-{T1} nop-{U1} ef-{V} g-{~} succ-{|e|}
                               / nop-{~3} e f-{T} succ-{|e|})

e <-- a b-{?T1} c-{?~3} d-{?U1} e (nop-{T1} nop-{U1} f-{V} g-{~} succ-{|e|}
                               / nop-{~3} f-{T} succ-{|e|})

e <-- a b-{?T1} c-{?~3} d-{?U1} e f-{?V1|?T2}
      (
        nop-{T1} nop-{U1} nop-{V1} g-{~} succ-{|e|} //
        nop-{~3} nop-{T2} succ-{|e|}
      )

# Finally we need to accumulate all of the nop operations into the head of the
# first non-nop term in each xord-term. (I'm sure there's a better way- but in
# any case, this is the final result:)

e <-- a b-{?T1} c-{?~3} d-{?U1} e f-{?V1|?T2}
      ( g-{T1}-{U1}-{V1}-{~} succ-{|e|} // succ-{~3}-{T2}-{|e|} )

--------------
Backtracking occurs when:
- ord instead of xord (including implied ord on star expressions)
- predicates because they don't consume anything

Data storage occurs when: ...
  (differentiate between "accumulating" data used in transforms- which doesn't
  count toward complexity, and data accumulated strictly to enable parsing /
  accepting of correct language)

Weak backtracking (data extracted more than once but linearly in a way that
doesn't increase complexity)

e <- (ab)* a
a <- #| Big monsterous time consuming expression |#

input: (equiv of a) (equiv of a)

# OLD WAY (WRONG WAY):
e <-  head (a b)* a tail
e <=- head s1 a tail
s1<=- a b s1 / succ

# RIGHT WAY:
e <-  head (a b)* a tail
e <=- head s1
s1<=- a b s1 / a tail
OR
e <-  (a b)* a tail
e <=- a b e / a tail

* Star expressions turn into recursive ords- but instead of the second term
  being succ, it is the tail of whatever came after the star expression in the
  context where it was first described. (Because this allows us to factor
  things out and turn it into an xord)
* When expression starts with a star expression, rewrite to recursive
  _in-place_.
* (Way to do essentially the same thing with left-recursion?)

----------------
TAGS / REFERENCES ON RECURSION, PLUS, & STAR EXPRESSIONS

e   -> T:f+ [@] V:f+ <- $T $V
f   -> [a-z] [0-9]

e  --> f-{e-T} f*-{e-T} [@]-{~} f-{e-V} f*-{e-V} succ-{|e|}
f  --> [a-z] [0-9]

e  --> f-{e-T} s1
s1 --> f-{e-T} s1 / [@]-{~} f-{e-V} f*-{e-V} succ-{|e|}
f  --> [a-z] [0-9]

e  --> f-{e-T} s1
s1 --> f-{e-T} s1 // [@]-{~} f-{e-V} s2
s2 --> f-{e-V} s1 // succ-{|e|}
f  --> [a-z] [0-9]

e  -=> [a-z] [0-9]-{e-T} s1
s1 -=> [a-z] [0-9]-{e-T} s1 // [@]-{~} [a-z] [0-9]-{e-V} s2
s2 -=> [a-z] [0-9]-{e-V} s2 // succ-{|($T $V)|}

----------------
Will it be possible to do proper factoring / reductions when inlining is
impossible because of recursion? And if I figure out a way to do it, does it
make general inlining irrelevant?

